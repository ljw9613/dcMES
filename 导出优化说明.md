# 检测数据导出优化说明

## 问题

- **数据导出**、**按物料导出**、**批量导出历史数据** 在数据量过大时：
  - 前端一次拉取全量，易 **HTTP 超时**、**浏览器内存不足**
  - 后端单次查询无 `limit`，**数据库压力大**，大结果集易超时
  - 导出 Excel 时整表在内存中构建，**容易卡死或失败**

## 优化思路：前端分批拉取 + 上限

本次采用 **前端分批拉取 + 条数上限** 的方式，不新增后端接口，改动集中在前端，便于落地。

### 1. 常量

- `exportBatchSize`: **5000** — 每批请求拉取条数
- `exportMaxRows`: **50000** — 单次导出最多条数，达上限即停止拉取并提示

### 2. 数据导出 / 按物料导出

| 场景 | 原逻辑 | 优化后 |
|------|--------|--------|
| 有物料/销售订单/流程状态 → 按条码查 | 按条码分批，每批 **无 limit**，全量拉取 | 每批 **limit 5000** 分页拉取，累计达 **5 万** 即停 |
| 无上述条件 → 直接按筛选条件查 | **无 limit**，一次拉全量 | **分批拉取**，每批 5000，最多 5 万条 |

- 新增 `fetchInspectionLastDataForExport`：对 `InspectionLastData` 做 **分批 + 上限** 拉取。
- `fetchInspectionDataAdvanced` 在导出模式下增加 **maxTotal**、**batchLimit**，在每个 scanCode 批次内 **skip/limit 分页**，并遵守 **maxTotal**。

### 3. 批量导出历史数据

| 环节 | 原逻辑 | 优化后 |
|------|--------|--------|
| 获取条码列表 | 从 `InspectionLastData` **无 limit** 全量查，再 `map` 取 `scanCode` | **limit 10000**，且 **select: "scanCode"**，只拉条码 |
| 拉取历史 | 按 50 个条码一批，每批 **无 limit**，全量 | 使用 **单 query** `scanCode: { $in: targetScanCodes }`，通过 **skip/limit 分批** 拉取，最多 **5 万** 条 |

- 新增 `fetchInspectionHistoryForExport`：对 `InspectionData` 按 **query + skip/limit** 分批拉取，并遵守 **maxRows**。

### 4. 提示与体验

- 导出前提示：**单批 5000 条、最多 5 万条**。
- 达上限时提示：**“数据量过大，已仅导出前 50,000 条，请缩小筛选条件以导出全部”**。
- 进度条仍按拉取进度更新。

### 5. 使用建议

- 尽量 **缩小筛选条件**（时间范围、设备、工序、扫描码等），使命中数据 &lt; 5 万，以便一次导出完整集合。
- 若必须导出更多，可 **按时间分段** 多次导出，再在 Excel 中合并。

## 后端流式导出（可选进阶）

若 5 万条上限仍不足，可考虑 **后端流式导出**：

- 新增接口如 `GET /api/v1/export/inspection-last-data`、`/export/inspection-history`。
- 后端用 **MongoDB cursor** + **aggregate $lookup** 流式生成 **CSV**（或 Excel 流），直接写入 `response`。
- 前端通过 **fetch + 流式读取** 或 **`<a download>`** 触发下载。

这样可避免前端内存占用、单次请求体过大和超时，支持更大数据量导出。实现成本相对较高，可按需迭代。

## 小结

- 当前优化：**前端分批 + 上限**，不改后端，立即缓解超时与内存问题。
- 导出数据 / 按物料导出 / 批量历史导出 均采用 **单批 5000、最多 5 万**，并统一提示用户缩小条件或分批导出。
